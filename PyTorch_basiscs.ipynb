{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "#transforms\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "## download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
    "\n",
    "## download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data',train=False,download=True,transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = BATCH_SIZE, shuffle = False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    # initialization to define all the parameters in the model to use and train\n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        \n",
    "        #28x28x1 => 26x26x32\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3)\n",
    "        self.d1 = nn.Linear(26*26*32,128)\n",
    "        self.d2 = nn.Linear(128,10)\n",
    "    # forward function helps to construct the computation graph from input to the output\n",
    "    def forward(self,x):\n",
    "        #32x1x28x28 => 32x32x26x26\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # flatten => 32 x (32*26*26)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        \n",
    "        # 32 x (32*26*26) => 32x128\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # logits => 32x10\n",
    "        logits = self.d2(x)\n",
    "        out = F.softmax(logits, dim = 1)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyModel()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "After defining the network parameters, model, and criterion, we can start writing the code for the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.4904 | Train Accuracy: 0.97\n",
      "Epoch: 1 | Loss: 1.4815 | Train Accuracy: 0.98\n",
      "Epoch: 2 | Loss: 1.4775 | Train Accuracy: 0.99\n",
      "Epoch: 3 | Loss: 1.4737 | Train Accuracy: 0.99\n",
      "Epoch: 4 | Loss: 1.4721 | Train Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    training_running_loss = 0.0\n",
    "    training_acc = 0.0\n",
    "    \n",
    "    # training step\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        ## forward + backprop + loss\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits,labels)\n",
    "        optimizer.zero_grad()         # set gradients to zero for all the variables. If we don't do it, the PyTorch will accumulate the gradients.\n",
    "        loss.backward()               # This line of code does the backpropagation and compute all the gradients.\n",
    "        \n",
    "        ## update model params\n",
    "        optimizer.step()              # Performing one step optimization on the defined parameters of the model\n",
    "        \n",
    "        training_running_loss += loss.detach().item() # accumulating the loss\n",
    "        training_acc += ((torch.argmax(logits,1)).flatten() == labels).type(torch.float).mean().item()\n",
    "    \n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
    "          %(epoch, training_running_loss/i, training_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obazgir\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.98\n",
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_acc = 0.0\n",
    "p = 0\n",
    "for i , (images, labels) in enumerate(testloader, 0):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    output = model(images)\n",
    "    test_acc += (torch.argmax(output, 1).flatten() == labels).type(torch.float).mean().item()\n",
    "    preds = torch.argmax(output,1).flatten().cpu().numpy()\n",
    "    l = labels.cpu().numpy()\n",
    "    p += metrics.precision_score(preds,l,average = 'macro')\n",
    "    \n",
    "print('precision: %.2f'%(p/i))\n",
    "print('Test Accuracy: %.2f'%(test_acc/i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
